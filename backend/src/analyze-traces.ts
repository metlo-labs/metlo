import mlog from "logger"
import { v4 as uuidv4 } from "uuid"
import { AppDataSource } from "data-source"
import { ApiEndpoint, DataField, Hosts } from "models"
import { Brackets, QueryRunner } from "typeorm"
import { QueuedApiTrace } from "@common/types"
import {
  endpointAddNumberParams,
  getEndpointToken,
  isSuspectedParamater,
  shouldSkipDataFields,
  skipAutoGeneratedMatch,
} from "utils"
import { getPathTokens } from "@common/utils"
import { RiskScore } from "@common/enums"
import { isQueryFailedError } from "utils/db"
import { MetloContext } from "types"
import {
  getEntityManager,
  getQB,
  insertValueBuilder,
  insertValuesBuilder,
} from "services/database/utils"
import { analyze as analyzeV2 } from "services/analyze/v2"
import { analyze } from "services/analyze/v1"
import {
  getCustomWordsCached,
  getHostBlockListCompiledCached,
  getHostMapCompiledCached,
  getPathBlockListCompiledCached,
} from "services/metlo-config"
import { RedisClient } from "utils/redis"
import { ENDPOINT_CALL_COUNT_HASH, ORG_ENDPOINT_CALL_COUNT } from "./constants"

export const shouldUpdateEndpoint = (
  prevRiskScore: RiskScore,
  prevLastActive: Date,
  apiEndpoint: ApiEndpoint,
) => {
  if (
    !prevRiskScore ||
    !prevLastActive ||
    !apiEndpoint?.lastActive ||
    !apiEndpoint?.riskScore
  ) {
    return true
  }
  return (
    prevRiskScore !== apiEndpoint.riskScore ||
    apiEndpoint.lastActive.getTime() - prevLastActive.getTime() > 30_000
  )
}

export const updateDataFields = async (
  ctx: MetloContext,
  dataFields: DataField[],
  queryRunner: QueryRunner,
) => {
  if (dataFields.length === 0) {
    return
  }
  try {
    await insertValuesBuilder(ctx, queryRunner, DataField, dataFields)
      .orUpdate(
        [
          "dataClasses",
          "scannerIdentified",
          "falsePositives",
          "dataType",
          "dataTag",
          "updatedAt",
          "lastSeen",
          "isNullable",
          "matches",
        ],
        [
          "dataSection",
          "dataPath",
          "apiEndpointUuid",
          "statusCode",
          "contentType",
        ],
      )
      .execute()
  } catch (err) {
    if (isQueryFailedError(err) && err.code === "23505") {
      await insertValuesBuilder(ctx, queryRunner, DataField, dataFields)
        .orUpdate(
          [
            "dataClasses",
            "scannerIdentified",
            "falsePositives",
            "dataType",
            "dataTag",
            "updatedAt",
            "lastSeen",
            "isNullable",
            "matches",
            "statusCode",
            "contentType",
          ],
          ["uuid"],
        )
        .execute()
    } else {
      throw err
    }
  }
}

const generateEndpoint = async (
  ctx: MetloContext,
  trace: QueuedApiTrace,
  queryRunner: QueryRunner,
  isGraphQl: boolean,
  hasValidEnterpriseLicense: boolean,
  analyzeFunc: (
    ctx: MetloContext,
    trace: QueuedApiTrace,
    apiEndpoint: ApiEndpoint,
    queryRunner: QueryRunner,
    newEndpoint: boolean,
    skipDataFields: boolean,
    hasValidEnterpriseLicense: boolean,
  ) => Promise<void>,
): Promise<void> => {
  const startGenerateEndpoint = performance.now()
  let paramNum = 1
  let parameterizedPath = ""
  let pathRegex = String.raw``
  if (isGraphQl) {
    parameterizedPath = trace.path
    pathRegex = trace.path
  } else {
    const pathTokens = getPathTokens(trace.path)
    for (let j = 0; j < pathTokens.length; j++) {
      const tokenString = pathTokens[j]
      if (tokenString === "/") {
        parameterizedPath += "/"
        pathRegex += "/"
      } else if (tokenString.length > 0) {
        const customWords = await getCustomWordsCached(ctx)
        if (isSuspectedParamater(customWords, tokenString)) {
          parameterizedPath += `/{param${paramNum}}`
          pathRegex += String.raw`/[^/]+`
          paramNum += 1
        } else {
          parameterizedPath += `/${tokenString}`
          pathRegex += String.raw`/${tokenString}`
        }
      }
    }
  }
  if (pathRegex.length > 0) {
    pathRegex = String.raw`^${pathRegex}(/)*$`
    const endpointToken = getEndpointToken(parameterizedPath)
    const apiEndpoint = new ApiEndpoint()
    apiEndpoint.uuid = uuidv4()
    apiEndpoint.path = parameterizedPath
    apiEndpoint.pathRegex = pathRegex
    apiEndpoint.host = trace.host
    apiEndpoint.method = trace.method
    apiEndpoint.token_0 = endpointToken.token_0
    apiEndpoint.token_1 = endpointToken.token_1
    apiEndpoint.token_2 = endpointToken.token_2
    apiEndpoint.token_3 = endpointToken.token_3
    apiEndpoint.token_4 = endpointToken.token_4
    apiEndpoint.token_5 = endpointToken.token_5
    endpointAddNumberParams(apiEndpoint)
    apiEndpoint.dataFields = []
    if (isGraphQl) {
      apiEndpoint.isGraphQl = true
      apiEndpoint.userSet = true
    }

    try {
      await queryRunner.startTransaction()
      await insertValueBuilder(ctx, queryRunner, Hosts, {
        host: trace.host,
        isPublic: false,
      })
        .orIgnore()
        .execute()
      await insertValueBuilder(
        ctx,
        queryRunner,
        ApiEndpoint,
        apiEndpoint,
      ).execute()
      await queryRunner.commitTransaction()
      mlog.time(
        "analyzer.insert_new_endpoint",
        performance.now() - startGenerateEndpoint,
      )

      await analyzeFunc(
        ctx,
        trace,
        apiEndpoint,
        queryRunner,
        true,
        false,
        hasValidEnterpriseLicense,
      )
      await setEndpointCalled(ctx, apiEndpoint.uuid)
    } catch (err) {
      if (queryRunner.isTransactionActive) {
        await queryRunner.rollbackTransaction()
      }
      if (isQueryFailedError(err) && err.code === "23505") {
        const existingEndpoint = await getEntityManager(
          ctx,
          queryRunner,
        ).findOne(ApiEndpoint, {
          where: {
            path: trace.path,
            host: trace.host,
            method: trace.method,
          },
          relations: { dataFields: true },
        })
        if (existingEndpoint) {
          const skipDataFields = await shouldSkipDataFields(
            ctx,
            existingEndpoint.uuid,
            trace.responseStatus,
          )
          await analyzeFunc(
            ctx,
            trace,
            existingEndpoint,
            queryRunner,
            false,
            skipDataFields,
            hasValidEnterpriseLicense,
          )
        }
      } else {
        mlog.withErr(err).error("Error generating new endpoint")
      }
    }
  }
}

let datasource = null
let queryRunner = null

const getDataSource = async () => {
  if (datasource == null) {
    datasource = await AppDataSource.initialize()
    mlog.info("AppDataSource Initialized...")
    mlog.info("Running Analyzer Worker...")
  }
  if (!datasource.isInitialized) {
    mlog.error("Couldn't initialize datasource...")
    throw new Error("Couldn't initialize datasource")
  }
  return datasource
}

const getQueryRunner = async () => {
  if (queryRunner === null) {
    queryRunner = (await getDataSource()).createQueryRunner()
    await queryRunner.connect()
  } else {
    if (queryRunner.isReleased) {
      queryRunner = (await getDataSource()).createQueryRunner()
      await queryRunner.connect()
    }
  }
  return queryRunner
}

const getMappedHost = async (task: {
  ctx: MetloContext
  host: string
  tracePath: string
}): Promise<{ mappedHost: string | null; isBlocked: boolean }> => {
  let mappedHost = null
  let isBlocked = false
  try {
    await getDataSource()
    let queryRunner = await getQueryRunner()
    const { ctx, host, tracePath } = task
    const start = performance.now()
    const hostMap = await getHostMapCompiledCached(ctx, queryRunner)
    mlog.time("analyzer.get_host_map", performance.now() - start)

    const startBlockList = performance.now()
    const hostBlockList = await getHostBlockListCompiledCached(ctx, queryRunner)
    mlog.time(
      "analyzer.get_host_block_list",
      performance.now() - startBlockList,
    )

    const startMatchHostMap = performance.now()
    for (const e of hostMap) {
      const match = host.match(e.pattern)
      if (match && match[0].length == host.length) {
        mappedHost = e.host
        break
      }
    }
    mlog.time("analyzer.match_host_map", performance.now() - startMatchHostMap)

    const startMatchBlockList = performance.now()
    for (const e of hostBlockList) {
      const match = e.test(mappedHost ?? host)
      if (match) {
        isBlocked = true
        break
      }
    }
    mlog.time(
      "analyzer.match_host_block_list",
      performance.now() - startMatchBlockList,
    )

    if (!isBlocked) {
      const startPathBlockList = performance.now()
      const pathBlockList = await getPathBlockListCompiledCached(
        ctx,
        queryRunner,
      )
      mlog.time(
        "analyzer.get_path_block_list",
        performance.now() - startPathBlockList,
      )

      const startMatchPathBlockList = performance.now()
      for (const item of pathBlockList) {
        const match = item.host.test(mappedHost ?? host)
        if (match) {
          for (const path of item.paths) {
            const matchPath = path.test(tracePath)
            if (matchPath) {
              isBlocked = true
              break
            }
          }
        }
      }
      mlog.time(
        "analyzer.match_path_block_list",
        performance.now() - startMatchPathBlockList,
      )
    }

    return { mappedHost, isBlocked }
  } catch (err) {
    mlog.withErr(err).error("Encountered error while processing trace host")
    if (queryRunner.isTransactionActive) {
      await queryRunner.rollbackTransaction()
    }
  }
}

const setEndpointCalled = async (ctx: MetloContext, endpointUUID: string) => {
  const start = performance.now()
  await RedisClient.incrementEndpointSeenUsage(
    ctx,
    endpointUUID,
    ENDPOINT_CALL_COUNT_HASH,
    ORG_ENDPOINT_CALL_COUNT,
  )
  mlog.time("analyzer.endpoint_hash_incr", performance.now() - start)
}

const analyzeTraces = async (task: {
  trace: QueuedApiTrace
  ctx: MetloContext
  version: number
  isGraphQl: boolean
  hasValidEnterpriseLicense: boolean
  apiEndpoint: ApiEndpoint
  skipDataFields: boolean
}) => {
  const start = performance.now()
  try {
    await getDataSource()
    let queryRunner = await getQueryRunner()
    const { trace, ctx, version, hasValidEnterpriseLicense, apiEndpoint } = task
    trace.createdAt = new Date(trace.createdAt)
    const analyzeFunc = version === 2 ? analyzeV2 : analyze
    const customWords = await getCustomWordsCached(ctx)
    if (
      apiEndpoint &&
      !skipAutoGeneratedMatch(customWords, apiEndpoint, trace.path)
    ) {
      const start2 = performance.now()
      const dataFields = task.skipDataFields
        ? []
        : await getEntityManager(ctx, queryRunner).find(DataField, {
            where: { apiEndpointUuid: apiEndpoint.uuid },
          })
      apiEndpoint.dataFields = dataFields
      mlog.time("analyzer.query_data_fields", performance.now() - start2)
      await analyzeFunc(
        ctx,
        trace,
        apiEndpoint,
        queryRunner,
        false,
        task.skipDataFields,
        hasValidEnterpriseLicense,
      )
      await setEndpointCalled(ctx, apiEndpoint.uuid)
    } else {
      if (trace.responseStatus !== 404 && trace.responseStatus !== 405) {
        await generateEndpoint(
          ctx,
          trace,
          queryRunner,
          task.isGraphQl,
          hasValidEnterpriseLicense,
          analyzeFunc,
        )
      }
    }
  } catch (err) {
    mlog.withErr(err).error("Encountered error while analyzing traces")
    if (queryRunner.isTransactionActive) {
      await queryRunner.rollbackTransaction()
    }
  }
  mlog.count("analyzer.trace_count")
  mlog.count("analyzer.full_trace_count")
  mlog.time("analyzer.total_analysis_func", performance.now() - start)
}

const analyzePartialBulk = async (task: {
  traces: QueuedApiTrace[]
  apiEndpointUUIDs: string[]
  ctx: MetloContext
}) => {
  const start = performance.now()
  const len = task.traces?.length ?? 0
  try {
    const { traces, ctx, apiEndpointUUIDs } = task
    let processedTraces: QueuedApiTrace[] = []
    let processedApiEndpointUuids: string[] = []
    for (let i = 0; i < traces.length; i++) {
      if (!apiEndpointUUIDs[i]) {
        continue
      }
      traces[i].createdAt = new Date(traces[i].createdAt)
      await setEndpointCalled(ctx, apiEndpointUUIDs[i])
      processedTraces.push(traces[i])
      processedApiEndpointUuids.push(apiEndpointUUIDs[i])
    }
  } catch (err) {
    mlog.withErr(err).error("Encountered error while analyzing traces")
  }
  mlog.count("analyzer.trace_count", len)
  mlog.count("analyzer.partial_trace_count", len)
  mlog.time("analyzer.total_analysis_func", performance.now() - start)
}

const getEndpoint = async (task: {
  trace: QueuedApiTrace
  ctx: MetloContext
}): Promise<ApiEndpoint> => {
  const start = performance.now()
  try {
    await getDataSource()
    let queryRunner = await getQueryRunner()
    const { trace, ctx } = task
    const pathTokens = trace.path?.split("/")
    if (pathTokens.length > 0 && pathTokens[0] === "") {
      pathTokens.shift()
    }
    let endpointQb = getQB(ctx, queryRunner)
      .from(ApiEndpoint, "endpoint")
      .andWhere("method = :method", { method: trace.method })
      .andWhere("host = :host", { host: trace.host })
    for (let i = 0; i <= 5; i++) {
      endpointQb = pathTokens[i]
        ? endpointQb.andWhere(
            new Brackets(qb => {
              qb.where(`token_${i} = '{param}'`).orWhere(
                `token_${i} = :token_${i}`,
                {
                  [`token_${i}`]: pathTokens[i],
                },
              )
            }),
          )
        : endpointQb.andWhere(`token_${i} IS NULL`)
    }
    if (pathTokens.length > 6) {
      endpointQb = endpointQb.andWhere(`:path ~ "pathRegex"`, {
        path: trace.path,
      })
    }
    const apiEndpoint: ApiEndpoint = await endpointQb
      .addOrderBy(`"numberParams"`, "ASC")
      .limit(1)
      .getRawOne()
    return apiEndpoint
  } catch (err) {
    mlog.withErr(err).error("Encountered error while querying endpoint")
    if (queryRunner.isTransactionActive) {
      await queryRunner.rollbackTransaction()
    }
  } finally {
    mlog.time("analyzer.query_endpoint", performance.now() - start)
  }
}

const runTaskInner = async (task: { type: string; task: any }) => {
  if (task.type == "analyze") {
    await analyzeTraces(task.task)
  } else if (task.type == "analyze_partial_bulk") {
    await analyzePartialBulk(task.task)
  } else if (task.type == "get_endpoint") {
    return await getEndpoint(task.task)
  } else if (task.type == "get_mapped_host") {
    return await getMappedHost(task.task)
  }
}

const runTask = async (task: { type: string; task: any }) => {
  if (Array.isArray(task.task)) {
    let out: any[] = []
    for (const taskElem of task.task) {
      const res = await runTaskInner({ ...task, task: taskElem })
      out.push(res)
    }
    return out
  } else {
    return await runTaskInner(task)
  }
}

export default runTask
